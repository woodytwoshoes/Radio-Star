{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from luigi import Task\n",
    "from luigi.parameter import BoolParameter, IntParameter\n",
    "from luigi.task import ExternalTask\n",
    "import luigi\n",
    "from csci_utils.luigi.dask.target import CSVTarget\n",
    "from csci_utils.luigi.dask.target import ParquetTarget\n",
    "from csci_utils.luigi.task import Requirement\n",
    "from csci_utils.luigi.task import Requires\n",
    "from csci_utils.luigi.task import TargetOutput\n",
    "from luigi.contrib.s3 import S3Target\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dask import dataframe as dd\n",
    "from sklearn.metrics.pairwise import cosine_similarity, nan_euclidean_distances\n",
    "from sklearn.preprocessing import LabelEncoder, normalize\n",
    "import dask.array as da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_objects_general(ddf, object_cols):\n",
    "    LE = LabelEncoder()\n",
    "    for object_col in object_cols:\n",
    "        ddf[object_col] = da.from_array(\n",
    "            LE.fit_transform(ddf[object_col].astype(str)))\n",
    "    return ddf\n",
    "\n",
    "def normalize_general(ddf,columns):\n",
    "    result = ddf.copy()\n",
    "    for feature_name in columns:\n",
    "        max_value = ddf[feature_name].max()\n",
    "        min_value = ddf[feature_name].min()\n",
    "        result[feature_name] = 2*(ddf[feature_name] - min_value) / (max_value - min_value) - 1\n",
    "    return result\n",
    "\n",
    "def normalize_chex(ddf, object_cols):\n",
    "    ddf = normalize_general(ddf,object_cols)\n",
    "    ddf =  normalize_general(ddf,['Age'])\n",
    "    return ddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChexpertDataframe(ExternalTask):\n",
    "\n",
    "    s3_path = 's3://radio-star-csci-e-29/unzipped/'\n",
    "\n",
    "    output = TargetOutput(\n",
    "        file_pattern=\"\",\n",
    "        ext=\"train.csv\",\n",
    "        target_class=S3Target,\n",
    "        path=s3_path\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'..\\\\data\\\\processed'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.relpath(('C:\\\\Users\\\\wmj\\\\PycharmProjects\\\\radio-star\\\\models\\\\Tasks\\\\', 'C:\\\\Users\\\\wmj\\\\PycharmProjects\\\\radio-star\\\\data\\\\processed\\\\')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProcessChexpertDfToParquet(Task):\n",
    "    requires = Requires()\n",
    "    chexpertdf = Requirement(ChexpertDataframe)\n",
    "\n",
    "    output = TargetOutput(\n",
    "        target_class=ParquetTarget,\n",
    "        path=\"../data/processed/\",\n",
    "        ext=\"\",\n",
    "        flag=False,\n",
    "        storage_options=dict(requester_pays=True),\n",
    "    )\n",
    "\n",
    "    def run(self):\n",
    "        pathCSV = self.input()[\"chexpertdf\"].path\n",
    "        ddf = dd.read_csv(pathCSV)\n",
    "        self.output().write_dask(ddf, compression=\"gzip\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormalizeDF(Task):\n",
    "    \"\"\"The Dataframe is best normalized before similarity calculations are\n",
    "    run on it.\"\"\"\n",
    "\n",
    "\n",
    "    requires = Requires()\n",
    "    proc_chexpertdf = Requirement(ProcessChexpertDfToParquet)\n",
    "\n",
    "    output = TargetOutput(\n",
    "        target_class=ParquetTarget,\n",
    "        path=\"../data/processed/\",\n",
    "        ext=\"\",\n",
    "        flag=False,\n",
    "        storage_options=dict(requester_pays=True),\n",
    "    )\n",
    "\n",
    "    def run(self):\n",
    "        ddf = self.input()[\"proc_chexpertdf\"].read_dask()\n",
    "        ddf_raw = ddf.copy()\n",
    "        ddf = ddf.drop(columns=['Path'])\n",
    "        object_cols = ddf.dtypes[(ddf.dtypes == object)].index.values\n",
    "\n",
    "        ddf = encode_objects_general(ddf, object_cols)\n",
    "\n",
    "        ddf = normalize_chex(ddf, object_cols)\n",
    "\n",
    "        self.output().write_dask(ddf, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FindSimilar(Task):\n",
    "    \"\"\"The Dataframe is best normalized before similarity calculations are\n",
    "    run on it.\"\"\"\n",
    "\n",
    "    requires = Requires()\n",
    "    proc_chexpertdf = Requirement(ProcessChexpertDfToParquet)\n",
    "    normalize_df = Requirement(NormalizeDF)\n",
    "    comparator_index = IntParameter(default = 37959)\n",
    "    n_images = IntParameter(default = 5)\n",
    "\n",
    "    output = TargetOutput(\n",
    "        target_class=ParquetTarget,\n",
    "        path=\"../data/processed/\",\n",
    "        ext=\"\",\n",
    "        flag=False,\n",
    "        storage_options=dict(requester_pays=True),\n",
    "    )\n",
    "\n",
    "    def run(self):\n",
    "        ddf = self.input()[\"normalize_df\"].read_dask()\n",
    "        ddf_raw = self.input()[\"proc_chexpertdf\"].read_dask()\n",
    "        \n",
    "        object_cols = ddf.dtypes[(ddf.dtypes == object)].index.values\n",
    "\n",
    "        row_comparator_raw = ddf.loc[self.comparator_index]\n",
    "\n",
    "        # This compensate for a bug in dask row equality calculations\n",
    "        row_comparator_na = row_comparator_raw.isna().compute().iloc[0]\n",
    "\n",
    "        similar_features_idx = (ddf.isna() == row_comparator_na).sum(\n",
    "            1).compute().nlargest(n=100).index\n",
    "\n",
    "        argsorted = nan_euclidean_distances(\n",
    "            row_comparator_raw.compute().values.reshape(1, -1),\n",
    "            ddf.loc[similar_features_idx.to_list()].compute().values).argsort()\n",
    "        \n",
    "        top_n = similar_features_idx[argsorted][0][:self.n_images]\n",
    "        \n",
    "        top_n_close_images = ddf_raw.loc[top_n]\n",
    "\n",
    "        self.output().write_dask(top_n_close_images, compression=\"gzip\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:requirements dict collected: {'normalize_df': NormalizeDF(), 'proc_chexpertdf': ProcessChexpertDfToParquet()},\n",
      "INFO:root:self.target_kwargs['path'] is ../data/processed/NormalizeDF\n",
      "INFO:root:BaseDaskTarget path is ../data/processed/NormalizeDF/\n",
      "INFO:root:self.target_kwargs['path'] is ../data/processed/ProcessChexpertDfToParquet\n",
      "INFO:root:BaseDaskTarget path is ../data/processed/ProcessChexpertDfToParquet/\n",
      "INFO:root:requirements dict collected: {'normalize_df': NormalizeDF(), 'proc_chexpertdf': ProcessChexpertDfToParquet()},\n",
      "INFO:root:self.target_kwargs['path'] is ../data/processed/NormalizeDF\n",
      "INFO:root:BaseDaskTarget path is ../data/processed/NormalizeDF/\n",
      "INFO:root:self.target_kwargs['path'] is ../data/processed/ProcessChexpertDfToParquet\n",
      "INFO:root:BaseDaskTarget path is ../data/processed/ProcessChexpertDfToParquet/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unadjusted path is:  ../data/processed/NormalizeDF\n",
      "read_parquet_path is:  ../data/processed/NormalizeDF\\*.parquet\n",
      "unadjusted path is:  ../data/processed/ProcessChexpertDfToParquet\n",
      "read_parquet_path is:  ../data/processed/ProcessChexpertDfToParquet\\*.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wmj\\.virtualenvs\\radio-star-X64HrzkT\\lib\\site-packages\\ipykernel_launcher.py:37: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "INFO:root:self.target_kwargs['path'] is ../data/processed/FindSimilar\n",
      "INFO:root:BaseDaskTarget path is ../data/processed/FindSimilar/\n",
      "INFO:luigi-interface:Writing dask collection to ../data/processed/FindSimilar/\n",
      "INFO:luigi-interface:Successfully wrote to ../data/processed/FindSimilar/, flagging complete\n"
     ]
    }
   ],
   "source": [
    "FindSimilar().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_of_interest = 37959"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:self.target_kwargs['path'] is ../data/processed/FindSimilar\n",
      "INFO:root:BaseDaskTarget path is ../data/processed/FindSimilar/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unadjusted path is:  ../data/processed/FindSimilar\n",
      "read_parquet_path is:  ../data/processed/FindSimilar\\*.parquet\n"
     ]
    }
   ],
   "source": [
    "ddf = FindSimilar().output().read_dask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Frontal/Lateral</th>\n",
       "      <th>AP/PA</th>\n",
       "      <th>No Finding</th>\n",
       "      <th>Enlarged Cardiomediastinum</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Lung Opacity</th>\n",
       "      <th>Lung Lesion</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Pneumothorax</th>\n",
       "      <th>Pleural Effusion</th>\n",
       "      <th>Pleural Other</th>\n",
       "      <th>Fracture</th>\n",
       "      <th>Support Devices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37959</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient09313/study1/...</td>\n",
       "      <td>Male</td>\n",
       "      <td>60</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>AP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17419</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient04352/study4/...</td>\n",
       "      <td>Male</td>\n",
       "      <td>60</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>AP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173799</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient40586/study11...</td>\n",
       "      <td>Male</td>\n",
       "      <td>53</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>AP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15509</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient03872/study2/...</td>\n",
       "      <td>Male</td>\n",
       "      <td>55</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>AP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216617</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient59195/study1/...</td>\n",
       "      <td>Female</td>\n",
       "      <td>60</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>AP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Path     Sex  Age  \\\n",
       "37959   CheXpert-v1.0-small/train/patient09313/study1/...    Male   60   \n",
       "17419   CheXpert-v1.0-small/train/patient04352/study4/...    Male   60   \n",
       "173799  CheXpert-v1.0-small/train/patient40586/study11...    Male   53   \n",
       "15509   CheXpert-v1.0-small/train/patient03872/study2/...    Male   55   \n",
       "216617  CheXpert-v1.0-small/train/patient59195/study1/...  Female   60   \n",
       "\n",
       "       Frontal/Lateral AP/PA  No Finding  Enlarged Cardiomediastinum  \\\n",
       "37959          Frontal    AP         NaN                         0.0   \n",
       "17419          Frontal    AP         NaN                         0.0   \n",
       "173799         Frontal    AP         NaN                        -1.0   \n",
       "15509          Frontal    AP         NaN                         0.0   \n",
       "216617         Frontal    AP         NaN                        -1.0   \n",
       "\n",
       "        Cardiomegaly  Lung Opacity  Lung Lesion  Edema  Consolidation  \\\n",
       "37959            NaN           1.0          1.0    1.0            1.0   \n",
       "17419            NaN           NaN          NaN    1.0            1.0   \n",
       "173799           NaN           NaN          1.0    1.0            1.0   \n",
       "15509            NaN           1.0          NaN    1.0            NaN   \n",
       "216617           NaN           1.0          1.0    1.0            1.0   \n",
       "\n",
       "        Pneumonia  Atelectasis  Pneumothorax  Pleural Effusion  Pleural Other  \\\n",
       "37959        -1.0         -1.0           0.0               1.0            NaN   \n",
       "17419        -1.0         -1.0           0.0               1.0            NaN   \n",
       "173799       -1.0         -1.0           0.0               1.0            NaN   \n",
       "15509        -1.0         -1.0           0.0               0.0            NaN   \n",
       "216617        NaN         -1.0           0.0               1.0            NaN   \n",
       "\n",
       "        Fracture  Support Devices  \n",
       "37959        NaN              1.0  \n",
       "17419        NaN              1.0  \n",
       "173799       NaN              1.0  \n",
       "15509        NaN              1.0  \n",
       "216617       NaN              1.0  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-virtualenv-name",
   "language": "python",
   "name": "my-virtualenv-name"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
